{"_type":"dict","title":"Embracing the Future of Work: How To Communicate Remotely","_key":"104186/1/1/0"}
{"_type":"dict","title":"How to Deploy Custom Docker Images for Your Web Crawlers","_key":"104186/1/1/1"}
{"_type":"dict","title":"Improved Frontera: Web Crawling at Scale with Python 3 Support","_key":"104186/1/1/2"}
{"_type":"dict","title":"How to Crawl the Web Politely with Scrapy","_key":"104186/1/1/3"}
{"_type":"dict","title":"Introducing Scrapy Cloud with Python 3 Support","_key":"104186/1/1/4"}
{"_type":"dict","title":"What the Suicide Squad Tells Us About Web Data","_key":"104186/1/1/5"}
{"_type":"dict","title":"This Month in Open Source at Scrapinghub August 2016","_key":"104186/1/1/6"}
{"_type":"dict","title":"Meet Parsel: the Selector Library behind Scrapy","_key":"104186/1/1/7"}
{"_type":"dict","title":"Incremental Crawls with Scrapy and DeltaFetch","_key":"104186/1/1/8"}
{"_type":"dict","title":"Improving Access to Peruvian Congress Bills with Scrapy","_key":"104186/1/1/9"}
{"_type":"dict","title":"Scrapely: The Brains Behind Portia Spiders","_key":"104186/1/1/10"}
{"_type":"dict","title":"Introducing Portia2Code: Portia Projects into Scrapy Spiders","_key":"104186/1/1/11"}
{"_type":"dict","title":"Scraping Infinite Scrolling Pages","_key":"104186/1/1/12"}
{"_type":"dict","title":"This Month in Open Source at Scrapinghub June 2016","_key":"104186/1/1/13"}
{"_type":"dict","title":"Introducing the Datasets Catalog","_key":"104186/1/1/14"}
{"_type":"dict","title":"Introducing the Crawlera Dashboard","_key":"104186/1/1/15"}
{"_type":"dict","title":"Data Extraction with Scrapy and Python 3","_key":"104186/1/1/16"}
{"_type":"dict","title":"How to Debug your Scrapy Spiders","_key":"104186/1/1/17"}
{"_type":"dict","title":"Scrapy + MonkeyLearn: Textual Analysis of Web Data","_key":"104186/1/1/18"}
{"_type":"dict","title":"Introducing Scrapy Cloud 2.0","_key":"104186/1/1/19"}
{"_type":"dict","title":"A (not so) Short Story on Getting Decent Internet Access","_key":"104186/1/1/20"}
{"_type":"dict","title":"Scraping Websites Based on ViewStates with Scrapy","_key":"104186/1/1/21"}
{"_type":"dict","title":"Machine Learning with Web Scraping: New MonkeyLearn Addon","_key":"104186/1/1/22"}
{"_type":"dict","title":"Mapping Corruption in the Panama Papers with Open Data","_key":"104186/1/1/23"}
{"_type":"dict","title":"Web Scraping to Create Open Data","_key":"104186/1/1/24"}
{"_type":"dict","title":"Scrapy Tips from the Pros: March 2016 Edition","_key":"104186/1/1/25"}
{"_type":"dict","title":"This Month in Open Source at Scrapinghub March 2016","_key":"104186/1/1/26"}
{"_type":"dict","title":"Join Scrapinghub for Google Summer of Code 2016","_key":"104186/1/1/27"}
{"_type":"dict","title":"How Web Scraping is Revealing Lobbying and Corruption in Peru","_key":"104186/1/1/28"}
{"_type":"dict","title":"Splash 2.0 Is Here with Qt 5 and Python 3","_key":"104186/1/1/29"}
{"_type":"dict","title":"Migrate your Kimono Projects to Portia","_key":"104186/1/1/30"}
{"_type":"dict","title":"Scrapy Tips from the Pros: February 2016 Edition","_key":"104186/1/1/31"}
{"_type":"dict","title":"Portia: The Open Source Alternative to Kimono Labs","_key":"104186/1/1/32"}
{"_type":"dict","title":"Web Scraping Finds Stores Guilty of Price Inflation","_key":"104186/1/1/33"}
{"_type":"dict","title":"Python 3 is Coming to Scrapy","_key":"104186/1/1/34"}
{"_type":"dict","title":"Happy Anniversary: Scrapinghub Turns 5","_key":"104186/1/1/35"}
{"_type":"dict","title":"Scrapy Tips from the Pros: Part 1","_key":"104186/1/1/36"}
{"_type":"dict","title":"Vizlegal: Rise of Machine-Readable Laws and Court Judgments","_key":"104186/1/1/37"}
{"_type":"dict","title":"Christmas Eve vs New Year’s Eve: Last Minute Price Inflation?","_key":"104186/1/1/38"}
{"_type":"dict","title":"Looking Back at 2015","_key":"104186/1/1/39"}
{"_type":"dict","title":"Winter Sales Showdown: Black Friday vs Cyber Monday vs Green Monday","_key":"104186/1/1/40"}
{"_type":"dict","title":"Chats With RINAR Solutions","_key":"104186/1/1/41"}
{"_type":"dict","title":"Black Friday, Cyber Monday: Are They Worth It?","_key":"104186/1/1/42"}
{"_type":"dict","title":"Tips for Creating a Cohesive Company Culture Remotely","_key":"104186/1/1/43"}
{"_type":"dict","title":"Parse Natural Language Dates with Dateparser","_key":"104186/1/1/44"}
{"_type":"dict","title":"Aduana: Link Analysis to Crawl the Web at Scale","_key":"104186/1/1/45"}
{"_type":"dict","title":"Scrapy on the Road to Python 3 Support","_key":"104186/1/1/46"}
{"_type":"dict","title":"Introducing Javascript support for Portia","_key":"104186/1/1/47"}
{"_type":"dict","title":"Distributed Frontera: Web Crawling at Scale","_key":"104186/1/1/48"}
{"_type":"dict","title":"The Road to Loading JavaScript in Portia","_key":"104186/1/1/49"}
{"_type":"dict","title":"EuroPython 2015","_key":"104186/1/1/50"}
{"_type":"dict","title":"StartupChats Remote Working Q&A","_key":"104186/1/1/51"}
{"_type":"dict","title":"PyCon Philippines 2015","_key":"104186/1/1/52"}
{"_type":"dict","title":"Google Summer of Code 2015","_key":"104186/1/1/53"}
{"_type":"dict","title":"Link Analysis Algorithms Explained","_key":"104186/1/1/54"}
{"_type":"dict","title":"EuroPython, here we go!","_key":"104186/1/1/55"}
{"_type":"dict","title":"Using git to manage vacations in a large distributed team","_key":"104186/1/1/56"}
{"_type":"dict","title":"Gender Inequality Across Programming Languages","_key":"104186/1/1/57"}
{"_type":"dict","title":"Traveling Tips for Remote Workers","_key":"104186/1/1/58"}
{"_type":"dict","title":"A Career in Remote Working","_key":"104186/1/1/59"}
{"_type":"dict","title":"Frontera: The Brain Behind the Crawls","_key":"104186/1/1/60"}
{"_type":"dict","title":"Scrape Data Visually with Portia and Scrapy Cloud","_key":"104186/1/1/61"}
{"_type":"dict","title":"Scrapinghub: A Remote Working Success Story","_key":"104186/1/1/62"}
{"_type":"dict","title":"Why we moved to Slack","_key":"104186/1/1/63"}
{"_type":"dict","title":"The History of Scrapinghub","_key":"104186/1/1/64"}
{"_type":"dict","title":"Skinfer: A Tool for Inferring JSON Schemas","_key":"104186/1/1/65"}
{"_type":"dict","title":"Handling JavaScript in Scrapy with Splash","_key":"104186/1/1/66"}
{"_type":"dict","title":"Scrapinghub Crawls the Deep Web","_key":"104186/1/1/67"}
{"_type":"dict","title":"New Changes to Our Scrapy Cloud Platform","_key":"104186/1/1/68"}
{"_type":"dict","title":"Introducing ScrapyRT: An API for Scrapy spiders","_key":"104186/1/1/69"}
{"_type":"dict","title":"Looking Back at 2014","_key":"104186/1/1/70"}
{"_type":"dict","title":"XPath Tips from the Web Scraping Trenches","_key":"104186/1/1/71"}
{"_type":"dict","title":"Introducing Data Reviews","_key":"104186/1/1/72"}
{"_type":"dict","title":"Extracting schema.org Microdata Using Scrapy Selectors and XPath","_key":"104186/1/1/73"}
{"_type":"dict","title":"Announcing Portia, the Open Source Visual Web Scraper!","_key":"104186/1/1/74"}
{"_type":"dict","title":"Optimizing Memory Usage of Scikit-Learn Models Using Succinct Tries","_key":"104186/1/1/75"}
{"_type":"dict","title":"Open Source at Scrapinghub","_key":"104186/1/1/76"}
{"_type":"dict","title":"Looking Back at 2013","_key":"104186/1/1/77"}
{"_type":"dict","title":"Marcos Campal Is a ScrapingHubber!","_key":"104186/1/1/78"}
{"_type":"dict","title":"Introducing Dash","_key":"104186/1/1/79"}
{"_type":"dict","title":"Why MongoDB Is a Bad Choice for Storing Our Scraped Data","_key":"104186/1/1/80"}
{"_type":"dict","title":"Introducing Crawlera, a Smart Page Downloader","_key":"104186/1/1/81"}
{"_type":"dict","title":"Git Workflow for Scrapy Projects","_key":"104186/1/1/82"}
{"_type":"dict","title":"Filling Login Forms Automatically","_key":"104186/1/1/83"}
{"_type":"dict","title":"Spiders activity graphs","_key":"104186/1/1/84"}
{"_type":"dict","title":"Finding Similar Items","_key":"104186/1/1/85"}
{"_type":"dict","title":"Scrapy 0.15 dropping support for Python 2.5","_key":"104186/1/1/86"}
{"_type":"dict","title":"Autoscraping casts a wider net","_key":"104186/1/1/87"}
{"_type":"dict","title":"Scrapy 0.14 released","_key":"104186/1/1/88"}
{"_type":"dict","title":"Dirbot – a new example Scrapy project","_key":"104186/1/1/89"}
{"_type":"dict","title":"Introducing w3lib and scrapely","_key":"104186/1/1/90"}
{"_type":"dict","title":"Scrapy 0.12 released","_key":"104186/1/1/91"}
{"_type":"dict","title":"Spoofing your Scrapy bot IP using tsocks","_key":"104186/1/1/92"}
{"_type":"dict","title":"Hello, world","_key":"104186/1/1/93"}
